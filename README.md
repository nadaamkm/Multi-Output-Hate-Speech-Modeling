# Multi-Output Hate Speech Modeling: Fine-Tuning Multilingual Transformer Architectures with Multi-Task Hierarchical Models and LIME Explainable AI

Detecting harmful content is critical for user safety and moderation on social media platforms. Online hate speech can spiral into real violence, as when unmoderated hate-speech on Facebook precipitated genocide in Myanmar in 2022. A robust hate speech detection model would be able to help analyze social behavior—for example, do women in fitness on instagram receive more hate comments than men? Most systems are optimized for English, (as Facebook’s was in Myanmar,) leaving other low resource or morphological complex languages like Arabic less protected. We propose a Multilingual Sentiment (Toxicity) Detection system to classify hostility sentiment, directness, and hate-targeted groups in social media comments across multiple languages (English, Arabic and French). The goal is to fine-tune existing NLP models to improve upon the performance achieved by existing efforts. 

Current hate speech detection models using BERT variants like mBERT and XLM-RoBERTa are mostly fine-tuned for modeling binary hate speech detection, or hate speech topics with limited classes. We extend this research for a multi-class, multi-label classification task, which includes a mix of multi-class outputs where each observation has exactly one label (hate speech, directness, target, group), and multi-label outputs where each observation has one or more labels (sentiment). Our multi-class, multi-label classification model achieves test prediiction with an 85% F1 score, and includes a mix of multi-class outputs where each row has exactly one label (hate speech, directness, target, group), and multi-label outputs where each row has one or more labels (sentiment). For comparison the single label hate speech classification task in English achieved a 99.5 F1 score. Employing LIME explanations on test predictions enables increased transparency for model decision making for each label and language. Addressing a larger multi-class hate-speech classification problem is a step towards building more inclusive, global NLP systems.
